name: Daily EDINET Extract

on:
  schedule:
    - cron: '0 15 * * *'  # 毎日日本時間 0:00 (UTC 15:00)
  workflow_dispatch:
    inputs:
      start_date:
        description: 'Start Date (YYYY-MM-DD)'
        required: true
        default: '2024-06-01'
      end_date:
        description: 'End Date (YYYY-MM-DD)'
        required: true
        default: '2024-06-30'

jobs:
  discovery:
    runs-on: ubuntu-latest
    outputs:
      matrix: ${{ steps.set-matrix.outputs.matrix }}
    steps:
      - uses: actions/checkout@v4
        with:
          submodules: 'recursive'
      - uses: actions/setup-python@v5
        with:
          python-version: '3.12'
          cache: 'pip'
      - name: Install dependencies
        run: pip install -r requirements.txt
      - id: set-matrix
        env:
          EDINET_API_KEY: ${{ secrets.EDINET_API_KEY }}
          EXTRACT_START: ${{ github.event.inputs.start_date || '2024-06-01' }}
          EXTRACT_END: ${{ github.event.inputs.end_date || '2024-06-30' }}
          DISABLE_PANDERA_IMPORT_WARNING: True
        run: |
          # マーカー（JSON_MATRIX_DATA:）を目印に JSON を取得
          RAW_JSON=$(python main.py --list-only --start "$EXTRACT_START" --end "$EXTRACT_END" | grep "^JSON_MATRIX_DATA:" | cut -d':' -f2-)
          DATA=${RAW_JSON:-"[]"}
          
          # 業種衝突を防ぎつつ均等分割するロジック
          python -c "
          import json, math, sys
          try:
              data = json.loads(sys.argv[1])
              if not data:
                  sys.stderr.write('\n' + '#' * 60 + '\n')
                  sys.stderr.write('  EDINET 抽出レポート: 書類が 0 件のため終了します\n')
                  sys.stderr.write('#' * 60 + '\n\n')
                  print('matrix=[]')
                  sys.exit(0)
              
              sec_map = {}
              for item in data:
                  s = item['sector']
                  sec_map.setdefault(s, []).append(item['id'])
              
              sorted_sectors = sorted(sec_map.keys(), key=lambda x: len(sec_map[x]), reverse=True)
              n, buckets, bucket_counts = 4, [[] for _ in range(4)], [0] * 4
              
              for s in sorted_sectors:
                  idx = bucket_counts.index(min(bucket_counts))
                  buckets[idx].extend(sec_map[s])
                  bucket_counts[idx] += len(sec_map[s])
              
              res = [{'ids': ','.join(b), 'idx': i, 'count': len(b)} for i, b in enumerate(buckets) if b]
              
              # レポート出力
              sys.stderr.write('\n' + '#' * 60 + '\n')
              sys.stderr.write('  EDINET 書類取得・ジョブ分割 レポート\n')
              sys.stderr.write('#' * 60 + '\n')
              sys.stderr.write(f'対象期間内の書類総数: {len(data)} 件\n')
              sys.stderr.write(f'分割ジョブ数: {len(res)}\n\n')
              for r in res:
                  sys.stderr.write(f'  - Job {r[\"idx\"]}: {r[\"count\"]} 件を担当\n')
              sys.stderr.write('#' * 60 + '\n\n')

              # 結果をGitHub Outputへ
              print(f'matrix={json.dumps(res)}')
          except Exception as e:
              sys.stderr.write(f'Error: {str(e)}\n')
              print('matrix=[]')
          " "$DATA" >> $GITHUB_OUTPUT

  extract:
    needs: discovery
    if: needs.discovery.outputs.matrix != '[]' && needs.discovery.outputs.matrix != ''
    runs-on: ubuntu-latest
    permissions:
      contents: write
    strategy:
      fail-fast: false
      matrix:
        chunk: ${{ fromJson(needs.discovery.outputs.matrix) }}
    timeout-minutes: 360
    
    steps:
      - uses: actions/checkout@v4
        with:
          submodules: 'recursive'
      - uses: actions/setup-python@v5
        with:
          python-version: '3.12'
          cache: 'pip'
      - name: Install dependencies
        run: pip install -r requirements.txt

      - name: Run Extraction
        env:
          EDINET_API_KEY: ${{ secrets.EDINET_API_KEY }}
          EXTRACT_START: ${{ github.event.inputs.start_date || '2024-06-01' }}
          EXTRACT_END: ${{ github.event.inputs.end_date || '2024-06-30' }}
        run: python main.py --start "$EXTRACT_START" --end "$EXTRACT_END" --id-list "${{ matrix.chunk.ids }}"

      - name: Commit and Push DB
        run: |
          git config --local user.email "github-actions[bot]@users.noreply.github.com"
          git config --local user.name "github-actions[bot]"
          git config --local core.quotepath false
          
          MAX_RETRIES=10
          RETRY_COUNT=0
          while [ $RETRY_COUNT -lt $MAX_RETRIES ]; do
            echo "Attempt $((RETRY_COUNT+1)): Updating local repository..."
            # 最新を取得。--autostash で解析済みの未コミットファイルを一時退避してマージ
            if git pull --rebase --autostash origin main; then
              echo "Checking for new database files in data/ ..."
              if [ -d "data" ] && [ "$(find data -name "*.db" | wc -l)" -gt 0 ]; then
                # gitignore を無視して全ての .db ファイルを強制的にステージング
                find data -name "*.db" -exec git add -f {} +
                
                if git diff --staged --quiet; then
                  echo "No new changes detected (files might be identical)."
                  break
                fi
                
                git commit -m "chore: Extract chunk ${{ matrix.chunk.idx }} (${{ matrix.chunk.count }} docs)"
                if git push origin main; then
                  echo "Successfully pushed data to main branch."
                  break
                fi
              else
                echo "No .db files found in data/ to commit."
                break
              fi
            else
              echo "Git pull failed, retrying..."
            fi
            
            RETRY_COUNT=$((RETRY_COUNT+1))
            WAIT_TIME=$((RANDOM % 20 + 10))
            echo "Collision detected or push failed. Waiting ${WAIT_TIME}s before retry $RETRY_COUNT/$MAX_RETRIES..."
            sleep $WAIT_TIME
          done
